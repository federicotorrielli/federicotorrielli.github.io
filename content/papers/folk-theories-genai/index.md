---
title: "How do people develop folk theories of generative AI text-to-image models?"
date: 2025-01-01
tags:
  [
    "Human-AI Interaction",
    "Generative AI",
    "Text-to-Image Models",
    "Folk Theories",
    "Qualitative Research",
  ]
author: ["C. D. Lodovico", "F. Torrielli", "L. D. Caro", "A. Rapp"]
description: "A qualitative study on how people strive to explain and make sense of GenAI text-to-image models. Published in International Journal of Human–Computer Interaction, 2025."
summary: "This paper presents a qualitative study exploring how people develop folk theories to explain and understand generative AI text-to-image models."
showToc: true
disableAnchoredHeadings: false
editPost:
  URL: "https://doi.org/10.1080/10447318.2025.2491009"
  Text: "International Journal of Human–Computer Interaction"
---

## Abstract

Generative Artificial Intelligence (GenAI) text-to-image models have made significant progress in emulating human-like outputs. However, understanding the inner functioning of these models remains a challenge due to their complexity and black-box nature. It has been observed that individuals naturally develop informal conceptualizations, termed "folk theories," to explain the behaviors of algorithmic systems. The specific nature of GenAI text-to-image models, which are obscure in their working principles, yet carry out activities that are peculiar to humans, makes it interesting to investigate people's theorization about this technology. With this aim, we conducted a qualitative interview study with 20 participants and observed how they accounted for the outputs of Stable Diffusion. The study findings show that participants developed a wide spectrum of conceptualizations, including folk theories that appear distinctive of GenAI text-to-image technology, also ascribing to the model a variety of "mental states." Furthermore, we found that theory building follows different inductive and deductive trajectories, with participants employing diverse strategies to explain the functioning of the technology.

---

## Citation

Chiara Di Lodovico, Federico Torrielli, Luigi Di Caro, and Amon Rapp, "How Do People Develop Folk Theories of Generative AI Text-to-Image Models? A Qualitative Study on How People Strive to Explain and Make Sense of GenAI," _International Journal of Human–Computer Interaction_, vol. 0, no. 0, pp. 1–25, 2025. DOI: [10.1080/10447318.2025.2491009](https://doi.org/10.1080/10447318.2025.2491009)

```BibTeX
@article{Di_Lodovico24042025,
	title        = {How Do People Develop Folk Theories of Generative AI Text-to-Image Models? A Qualitative Study on How People Strive to Explain and Make Sense of GenAI},
	author       = {Chiara Di Lodovico and Federico Torrielli and Luigi Di Caro and Amon Rapp and},
	year         = 2025,
	journal      = {International Journal of Human–Computer Interaction},
	publisher    = {Taylor \& Francis},
	volume       = {0},
	number       = {0},
	pages        = {1--25},
	doi          = {10.1080/10447318.2025.2491009},
	url          = {https://doi.org/10.1080/10447318.2025.2491009},
	eprint       = {https://doi.org/10.1080/10447318.2025.2491009}
}
```

---

## Links

- [Paper (DOI)](https://doi.org/10.1080/10447318.2025.2491009)
